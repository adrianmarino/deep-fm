#!/bin/python
# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# Imports
# -----------------------------------------------------------------------------
import sys

sys.path.append('./src')

import torch
import warnings

warnings.filterwarnings("ignore")

import logging
from bunch import Bunch
from torch.utils.data import DataLoader

from pytorch_common.callbacks import EarlyStop, ReduceLROnPlateau, Validation
from pytorch_common.callbacks.output import Logger

from pytorch_common.callbacks import SaveBestModel

from dataset.movielens import MovieLens1MDataset, MovieLens20MDataset
from modules import DeepFM
from pytorch_common.modules import Fn
from pytorch_common.util import train_val_split, set_device_name, set_device_memory, get_device, LoggerBuilder

from sklearn.metrics import roc_auc_score

import click

from torch.nn import BCELoss
from torch.optim import Adam

from pytorch_common.kfoldcv import StratifiedKFoldCV

from torch.utils.data import Subset


# -----------------------------------------------------------------------------
#
#
#
#
#
# -----------------------------------------------------------------------------
# Functions
# -----------------------------------------------------------------------------
def cv_train_fn(train_subset, train_idx, val_idx, ps, fold):
    model = DeepFM(
        ps.features_n_values,
        ps.embedding_size,
        ps.units_per_layer,
        ps.dropout
    ).to(ps.device)

    train_set = DataLoader(Subset(train_subset, train_idx), ps.batch_size, num_workers=ps.num_workers)
    val_set = DataLoader(Subset(train_subset, val_idx), ps.batch_size, num_workers=ps.num_workers)

    result = model.fit(
        train_set,
        loss_fn=BCELoss(),
        epochs=ps.epochs,
        optimizer=Adam(
            params=model.parameters(),
            lr=ps.lr,
            weight_decay=ps.weight_decay
        ),
        callbacks=[
            Validation(
                val_set,
                metrics={
                    'val_loss': lambda y_pred, y_true: BCELoss()(y_pred, y_true).item(),
                    'val_auc': lambda y_pred, y_true: roc_auc_score(y_true.cpu().numpy(), y_pred.cpu().numpy())
                },
                each_n_epochs=1
            ),
            Logger(['fold', 'time', 'epoch', 'train_loss', 'val_loss', 'val_auc', 'patience', 'lr']),
            ReduceLROnPlateau(metric='val_auc', mode='max', factor=ps.lr_factor, patience=ps.lr_patience),
            EarlyStop(metric='val_auc', mode='max', patience=3)
        ],
        extra_ctx={'fold': fold + 1}
    )

    return result.val_auc


def load_dataset(name):
    if '1m' == name:
        dataset_path = './datasets/ml-1m/ratings.dat'
        dataset = MovieLens1MDataset(dataset_path=dataset_path)
    else:
        dataset_path = './datasets/ml-20m/ratings.csv'
        dataset = MovieLens20MDataset(dataset_path=dataset_path)

    logging.info('{} dataset loaded! Shape: {}'.format(dataset_path, dataset.shape))

    return dataset


def validation(model, params, test_subset):
    logging.info('Model test evaluation...')
    test_data_loader = DataLoader(
        test_subset,
        params.batch_size,
        num_workers=params.num_workers * 2
    )
    score = Fn.validation_score(model, test_data_loader, get_device(), roc_auc_score)
    logging.info('Test score: {}'.format(score))


def train(params, train_subset):
    logging.info('Final model training (training + validation)...')
    epochs = 20
    model = DeepFM(
        params.features_n_values,
        params.embedding_size,
        params.units_per_layer,
        params.dropout
    ).to(params.device)
    summary = model.fit(
        data_loader=DataLoader(
            train_subset,
            params.batch_size,
            num_workers=params.num_workers * 2
        ),
        loss_fn=BCELoss(),
        epochs=epochs,
        optimizer=Adam(
            params=model.parameters(),
            lr=params.lr,
            weight_decay=params.weight_decay
        ),
        callbacks=[SaveBestModel(metric='val_loss')]
    )
    logging.info('summary: {}'.format(summary.items()))
    return summary


def cross_validation(cv_n_folds, params, train_subset):
    cv = StratifiedKFoldCV(
        cv_train_fn,
        get_y_values_fn=lambda ss: ss.dataset.targets[train_subset.indices],
        k_fold=cv_n_folds
    )
    logging.info('CV training...')
    result = cv.train(train_subset, params)
    logging.info('CV results: {}'.format(result))


# -----------------------------------------------------------------------------
#
#
#
#
#
# -----------------------------------------------------------------------------
# Main
# -----------------------------------------------------------------------------
@click.command()
@click.option(
    '--device',
    default='gpu',
    help='Device used to functions and optimize model. Values: gpu(default) or cpu.'
)
@click.option(
    '--cuda-process-memory-fraction',
    default=0.5,
    help='Setup max memory user per CUDA process. Percentage expressed between 0 and 1(default: 0.5).'
)
@click.option('--dataset', default='1m', help='Select movie lens dataset type. Values: 1m(default), 20m.')
@click.option('--cv-n-folds', default=10, help='cross validation n folds(default: 10).')
@click.option('--train-percent', default=0.7, help='Observations percent to used on training process(default: 0.7).')
def main(device, cuda_process_memory_fraction, dataset, cv_n_folds, train_percent):
    LoggerBuilder().on_console().build()

    set_device_name(device)
    set_device_memory(device, cuda_process_memory_fraction)

    ds = load_dataset(dataset)
    train_subset, test_subset = train_val_split(ds, train_percent=train_percent)

    params = Bunch({
        'seed': 42,
        'lr': 0.01,
        'lr_factor': 0.1,
        'lr_patience': 1,
        'weight_decay': 1e-6,
        'epochs': 50,
        'embedding_size': 50,
        'units_per_layer': [200, 200, 200],
        'dropout': 0.8,
        'batch_size': 4000,
        'num_workers': 12,
        'features_n_values': ds.field_dims,
        'device': get_device()
    })

    cross_validation(cv_n_folds, params, train_subset)

    train_summary = train(params, train_subset)

    # Load best model...
    best_model = train_summary.model
    best_model.load_state_dict(torch.load(train_summary.best_model_path))

    validation(best_model, params, test_subset)


if __name__ == '__main__':
    main()
# -----------------------------------------------------------------------------
